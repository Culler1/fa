{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refined keywords = 'Gender','sex',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "# Clearfield Area SD\n",
      "############\n",
      "Exception occurred for base URL https://go.boarddocs.com/pa/clea/Board.nsf/public, TimeoutException, Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010069baf8 chromedriver + 4987640\n",
      "1   chromedriver                        0x0000000100692eb3 chromedriver + 4951731\n",
      "2   chromedriver                        0x00000001002468d7 chromedriver + 444631\n",
      "3   chromedriver                        0x000000010028c985 chromedriver + 731525\n",
      "4   chromedriver                        0x000000010028cb41 chromedriver + 731969\n",
      "5   chromedriver                        0x00000001002d07c4 chromedriver + 1009604\n",
      "6   chromedriver                        0x00000001002b2b3d chromedriver + 887613\n",
      "7   chromedriver                        0x00000001002cdd31 chromedriver + 998705\n",
      "8   chromedriver                        0x00000001002b28e3 chromedriver + 887011\n",
      "9   chromedriver                        0x000000010027e9b9 chromedriver + 674233\n",
      "10  chromedriver                        0x000000010027fb9e chromedriver + 678814\n",
      "11  chromedriver                        0x0000000100657dc9 chromedriver + 4709833\n",
      "12  chromedriver                        0x000000010065cde4 chromedriver + 4730340\n",
      "13  chromedriver                        0x0000000100663c99 chromedriver + 4758681\n",
      "14  chromedriver                        0x000000010065db3a chromedriver + 4733754\n",
      "15  chromedriver                        0x000000010063135c chromedriver + 4551516\n",
      "16  chromedriver                        0x000000010067b908 chromedriver + 4856072\n",
      "17  chromedriver                        0x000000010067ba87 chromedriver + 4856455\n",
      "18  chromedriver                        0x000000010068bdef chromedriver + 4922863\n",
      "19  libsystem_pthread.dylib             0x00007ff811a0f4e1 _pthread_start + 125\n",
      "20  libsystem_pthread.dylib             0x00007ff811a0af6b thread_start + 15\n",
      "\n",
      "üèÅ Took 23.698608486971352 to run script.\n",
      "Extracted data written to policy1_extracted_data_2023-09-01.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# Read in the main database\n",
    "a1 = pd.read_csv(\"school_mainPA.csv\")\n",
    "# a1 = a1[0:25]\n",
    "a1 = a1[0:1]\n",
    "\n",
    "# keywords = [\"sexuality\",'at birth','male puberty','Biological','Critical race theory',\n",
    "#             'Partisan','Political','Indoctrination','Advocacy','Flag','Social policy','Race',\n",
    "#             'Racial','Controversial','Profanity','Sexual conduct','Graphic violence','Age-inappropriate',\n",
    "#             'Age-appropriate','Sexual acts','Sexualized','Nudity','LGBTQ','Gender ideology','sex assigned at birth',\n",
    "#             '3101','6312(g)','Implied depictions of sexual acts',\n",
    "#             'Partisan, Political, or Social Policy Advocacy', 'Neutrality']\n",
    "\n",
    "keywords = [\"gender theory\",'holocaust denial','critical theory','at birth','male puberty','Critical race theory','Indoctrination','Social policy',\n",
    "            'Racial','Controversial','Profanity','obscene','Graphic violence','transgender','cisgender',\n",
    "            'Age-appropriate','Gender ideology','sex assigned at birth',\n",
    "            '3101','6312(g)','Implied depictions of sexual acts','social justice',\n",
    "            'Partisan, Political, or Social Policy Advocacy', 'Neutrality']\n",
    "\n",
    "# DataFrame to store the extracted data\n",
    "extracted_data = pd.DataFrame(columns=['School District', 'County', 'URL', 'Text Content', 'Keywords Found', 'Number of Keywords Found'])\n",
    "\n",
    "# Get the current date for file naming\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "csv_filename = f\"policy1_extracted_data_{current_date}.csv\"\n",
    "\n",
    "# Using csv module instead of Pandas\n",
    "with open(csv_filename, 'w') as outfile:\n",
    "    fieldnames = ['School District', 'County', 'URL', 'Text Content', 'Keywords Found', 'Number of Keywords Found']\n",
    "    policy_writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    policy_writer.writeheader()\n",
    "\n",
    "    # Loop through each row in the DataFrame\n",
    "    for index, row in a1.iterrows():\n",
    "        district = row['school_dis']\n",
    "        county = row['cty_name']\n",
    "        url = row['base_link']\n",
    "        print(\n",
    "            f'############\\n'\n",
    "            f'# {district}\\n'\n",
    "            f'############'\n",
    "        )\n",
    "    \n",
    "        try:\n",
    "            t0 = time.perf_counter()\n",
    "            driver = webdriver.Chrome()\n",
    "            driver.get(url)\n",
    "            \n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.ID, \"li-policies\"))\n",
    "            )\n",
    "            policies_link = driver.find_element(By.ID, \"li-policies\")\n",
    "            # policies_link.click()\n",
    "            driver.execute_script('arguments[0].click()', policies_link)\n",
    "\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"policy-accordion\"))\n",
    "            )\n",
    "\n",
    "            soup_outer = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            href_elements = soup_outer.findChildren(attrs={'href': '#', 'unique': True})\n",
    "            unique_values = [element.get(\"unique\") for element in href_elements]\n",
    "\n",
    "            for unique_value in unique_values:\n",
    "                new_url = row['prePolicyID'] + unique_value\n",
    "                try:\n",
    "                    response = requests.get(new_url)\n",
    "                    response.raise_for_status()  # Raise an exception if the response status code is not 200\n",
    "    \n",
    "                    soup_inner = BeautifulSoup(response.content, \"html.parser\")\n",
    "                    print(f'Current unique_value: {unique_value}, {soup_inner.title.text}')\n",
    "                    container_div = soup_inner.find('div', id='policy-content')\n",
    "                    if container_div is not None:\n",
    "                        text_content = container_div.get_text(\" \", strip=True)\n",
    "                        # found_keywords = [keyword for keyword in keywords if re.search(r'\\b{}\\b'.format(re.escape(keyword)), text_content, re.IGNORECASE)]\n",
    "                        found_keywords = [keyword for keyword in keywords if keyword.lower() in text_content.lower()]\n",
    "                        if found_keywords:\n",
    "                            try:\n",
    "                                policy_writer.writerow({\n",
    "                                    'School District': district,\n",
    "                                    'County': county,\n",
    "                                    'URL': new_url,\n",
    "                                    'Keywords Found': found_keywords,\n",
    "                                    'Number of Keywords Found': len(found_keywords)\n",
    "                                })\n",
    "                                print(f'Wrote out policy {soup_inner.title.text}')\n",
    "                            except Exception as error:\n",
    "                                print(type(error).__name__, error, unique_value, soup_inner.title.text)\n",
    "                    else:\n",
    "                        print(\"Container div not found for\", new_url)\n",
    "                except Exception as e:\n",
    "                    # Handle any exception\n",
    "                    print(f\"Exception occurred: {str(e)}. Saving current data to CSV...\")\n",
    "                    extracted_data.to_csv('extracted_data_crashedp1.csv', index=False)\n",
    "                    print(\"Data saved. Script crashed.\")\n",
    "                \n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"Failed to fetch data from {new_url}: {str(e)}\")\n",
    "                \n",
    "                except KeyboardInterrupt:\n",
    "                    # Handle KeyboardInterrupt (Ctrl + C)\n",
    "                    print(\"KeyboardInterrupt detected. Saving current data to CSV...\")\n",
    "                    extracted_data.to_csv('extracted_data_interruptedp1.csv', index=False)\n",
    "                    print(\"Data saved. Script interrupted.\")\n",
    "    \n",
    "                # time.sleep(2)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred for base URL {url}, {type(e).__name__}, {str(e)}\")\n",
    "    \n",
    "        finally:\n",
    "            driver.quit()\n",
    "        t1 = time.perf_counter()\n",
    "        print('üèÅ Took', t1-t0, 'to run script.')\n",
    "        print(f'Extracted data written to {csv_filename}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
